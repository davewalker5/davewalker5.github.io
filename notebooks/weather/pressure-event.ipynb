{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESSURE_DERIV_WINDOW = \"1h\"    # Derivative derivation window\n",
    "DROP_THRESHOLD = -1.5           # hPa per window\n",
    "RISE_THRESHOLD =  1.5           # hPa per window\n",
    "GAP_THRESHOLD = \"2min\"          # Threshold for identifying data gaps\n",
    "DAYS = 30                       # Time period over which to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb43151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../pathutils.ipynb\n",
    "%run ../database.ipynb\n",
    "%run ../export.ipynb\n",
    "%run health.ipynb\n",
    "%run database.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_front_events(mask, tendency):\n",
    "    events = []\n",
    "    in_event = False\n",
    "    start = None\n",
    "    peak_time = None\n",
    "    peak_value = None\n",
    "    \n",
    "    for ts, is_event in mask.items():\n",
    "        if is_event and not in_event:\n",
    "            # start of event\n",
    "            in_event = True\n",
    "            start = ts\n",
    "            peak_time = ts\n",
    "            peak_value = tendency.loc[ts]\n",
    "            \n",
    "        elif is_event and in_event:\n",
    "            # update peak intensity\n",
    "            if tendency.loc[ts] < peak_value:   # for drops: more negative = stronger\n",
    "                peak_value = tendency.loc[ts]\n",
    "                peak_time = ts\n",
    "                \n",
    "        elif not is_event and in_event:\n",
    "            # event ends\n",
    "            end = ts\n",
    "            events.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'peak_time': peak_time,\n",
    "                'peak_change': peak_value\n",
    "            })\n",
    "            in_event = False\n",
    "    \n",
    "    # close if still ongoing\n",
    "    if in_event:\n",
    "        end = mask.index[-1]\n",
    "        events.append({\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'peak_time': peak_time,\n",
    "            'peak_change': peak_value\n",
    "        })\n",
    "\n",
    "    # Convert to a data frame and make sure the dates and times don't have timezone information associate with them\n",
    "    df = pd.DataFrame(events)\n",
    "    df[\"start\"] = (\n",
    "        pd.to_datetime(df[\"start\"], utc=True)       # ensure datetime with tz\n",
    "        .dt.tz_convert(None)                        # drop timezone\n",
    "    )\n",
    "\n",
    "    df[\"end\"] = (\n",
    "        pd.to_datetime(df[\"end\"], utc=True)         # ensure datetime with tz\n",
    "        .dt.tz_convert(None)                        # drop timezone\n",
    "    )\n",
    "\n",
    "    df[\"peak_time\"] = (\n",
    "        pd.to_datetime(df[\"peak_time\"], utc=True)   # ensure datetime with tz\n",
    "        .dt.tz_convert(None)                        # drop timezone\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the readings for each sensor and produce a combined data frame\n",
    "bme280_df = load_sensor_readings(\"bme280\")\n",
    "veml7700_df = load_sensor_readings(\"veml7700\")\n",
    "sgp40_df = load_sensor_readings(\"sgp40\")\n",
    "combined_df = merge_sensor_readings([bme280_df, veml7700_df, sgp40_df])\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a319914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bef98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate pressure derivative over the window\n",
    "combined_df['pressure_change'] = combined_df['pressure'].diff()\n",
    "combined_df['pressure_change_hr'] = combined_df['pressure'].diff().rolling(PRESSURE_DERIV_WINDOW).sum()\n",
    "\n",
    "# Detect rapid drops and rises\n",
    "combined_df['front_low']  = combined_df['pressure_change_hr'] < DROP_THRESHOLD\n",
    "combined_df['front_high'] = combined_df['pressure_change_hr'] > RISE_THRESHOLD\n",
    "\n",
    "combined_df['front_low'] = (\n",
    "    combined_df['front_low']\n",
    "      .astype(float)\n",
    "      .rolling(3, center=True)\n",
    "      .max()\n",
    "      .fillna(0)\n",
    "      .astype(bool)\n",
    ")\n",
    "\n",
    "combined_df['front_high'] = (\n",
    "    combined_df['front_high']\n",
    "      .astype(float)\n",
    "      .rolling(3, center=True)\n",
    "      .max()\n",
    "      .fillna(0)\n",
    "      .astype(bool)\n",
    ")\n",
    "\n",
    "# Detect weather front events\n",
    "low_fronts = extract_front_events(combined_df['front_low'], combined_df['pressure_change_hr'])\n",
    "high_fronts = extract_front_events(combined_df['front_high'], combined_df['pressure_change_hr'])\n",
    "\n",
    "# Smooth the data for plotting\n",
    "combined_df['pressure_smooth'] = combined_df['pressure'].rolling('30min', center=True).mean()\n",
    "combined_df['pressure_change_smooth'] = combined_df['pressure_change_hr'].rolling('1h', center=True).mean()\n",
    "\n",
    "# Calculate the time delta between samples and identify gaps larger than expected\n",
    "combined_df['dt'] = pd.to_timedelta(combined_df.index.diff(), errors='coerce')\n",
    "combined_df['is_gap'] = combined_df['dt'] > pd.Timedelta(GAP_THRESHOLD)\n",
    "\n",
    "display(combined_df.head())\n",
    "\n",
    "# Create a gaps dataframe\n",
    "gaps = combined_df[combined_df['is_gap']].copy()\n",
    "if not gaps.empty:\n",
    "    gaps[\"gap_end\"] = gaps.index\n",
    "\n",
    "    prev_index = combined_df.index.to_series().shift(1)\n",
    "\n",
    "    # Robust: align by index, guaranteed Series of timestamps (or NaT)\n",
    "    gaps[\"gap_start\"] = prev_index.reindex(gaps.index)\n",
    "\n",
    "    # Make sure both are proper UTC-aware datetimes\n",
    "    gaps[\"gap_start\"] = pd.to_datetime(gaps[\"gap_start\"], utc=True)\n",
    "    gaps[\"gap_end\"]   = pd.to_datetime(gaps[\"gap_end\"],   utc=True)\n",
    "\n",
    "# For each gap, mask values inside the interval with NaN so matplotlib won't draw lines across gaps\n",
    "for _, row in gaps.iterrows():\n",
    "  mask = (combined_df.index >= row[\"gap_start\"]) & (combined_df.index <= row[\"gap_end\"])\n",
    "  combined_df.loc[mask, \"pressure_smooth\"] = np.nan\n",
    "  combined_df.loc[mask, \"pressure_change_smooth\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb12b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the export folder path\n",
    "export_folder_path = get_export_folder_path(\"analysis\")\n",
    "\n",
    "display(low_fronts.head())\n",
    "\n",
    "# Strip the timezone from the timestamp, as this will cause the export to spreadsheet to fail (Excel can't\n",
    "# handle dates with timezone information)\n",
    "combined_df.index = combined_df.index.tz_localize(None)\n",
    "\n",
    "# Export the data to a spreadsheet\n",
    "export_to_spreadsheet(export_folder_path, \"bme280_pressure_pressure_event.xlsx\", {\n",
    "    \"Data\": combined_df,\n",
    "    \"Low Pressure Events\": low_fronts,\n",
    "    \"High Pressure Events\": high_fronts\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e82842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Left axis: pressure (blue)\n",
    "ax1.plot(combined_df.index, combined_df['pressure_smooth'], color='blue', label='Pressure (hPa)')\n",
    "ax1.set_ylabel(\"Pressure (hPa)\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Right axis: pressure-change (red/green)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Pressure Change (hPa/hr)\")\n",
    "\n",
    "# Plot pressure tendency\n",
    "ax2.plot(combined_df.index, combined_df['pressure_change_smooth'], color='gray', alpha=0.4)\n",
    "\n",
    "# Add peaks â€” note they now use ax2\n",
    "ax2.scatter(low_fronts['peak_time'], \n",
    "            low_fronts['peak_change'], \n",
    "            color='red', \n",
    "            label='Low-pressure front')\n",
    "\n",
    "ax2.scatter(high_fronts['peak_time'], \n",
    "            high_fronts['peak_change'], \n",
    "            color='green', \n",
    "            label='High-pressure front')\n",
    "\n",
    "# Add shaded areas across both axes\n",
    "for _, evt in low_fronts.iterrows():\n",
    "    ax1.axvspan(evt['start'], evt['end'], color='red', alpha=0.15)\n",
    "\n",
    "for _, evt in high_fronts.iterrows():\n",
    "    ax1.axvspan(evt['start'], evt['end'], color='green', alpha=0.15)\n",
    "\n",
    "# Legend handling\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Export to PNG or PDF, if required\n",
    "export_chart(export_folder_path, \"bme280_pressure_pressure_event\", \"png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
